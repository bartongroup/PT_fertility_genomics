#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
prioritise_druggable_sperm_targets_from_master_excel.py

Prioritise candidate druggable sperm targets from a single "master" Excel file
generated by:

  make_master_fertility_results_summary.py
  annotate_sperm_biochemical_accessibility.py

This script reads gene-level evidence from an Excel workbook (XLSX), using:
- Gene_Master (primary per-gene table; should include biochemical_accessibility_score)
- Tier_Summary_With_Omics (boolean membership across evidence tiers / sets)

It computes an auditable priority score using a transparent weighted sum:
- list/tier membership count (across boolean membership columns)
- proteomics evidence (Detected/Strong where available; otherwise Detected if present)
- Open Targets tractability annotations if present (small molecule / antibody / PROTAC)
- biochemical accessibility score (continuous; auto-scaled if 0-100)

It produces:
- <out_prefix>.tsv and <out_prefix>.xlsx (ranked output)
- <out_prefix>__candidate_druggable_sperm_protein.tsv/.xlsx
- optional <out_prefix>__topN.tsv/.xlsx if --top_n > 0

All TSV outputs are tab-separated.

Notes
-----
- This script is conservative: it ranks candidates for follow-up rather than
  asserting druggability.
- The score is auditable via the 'score_components' column.
"""

from __future__ import annotations

import argparse
import logging
import os
import re
from dataclasses import dataclass
from datetime import datetime
from typing import Dict, List, Optional, Sequence, Set, Tuple

import numpy as np
import pandas as pd


@dataclass(frozen=True)
class Weights:
    """Weights controlling the priority scoring model."""
    per_membership_true: float = 1.0
    proteomics_detected: float = 1.0
    proteomics_strong: float = 3.0
    tract_small_molecule: float = 4.0
    tract_antibody: float = 2.0
    tract_protac: float = 2.0
    novelty_bonus: float = 1.5
    biochemical_accessibility: float = 3.0


def setup_logger(verbose: bool) -> None:
    """
    Configure logging.

    Parameters
    ----------
    verbose
        If True, enable DEBUG logging.
    """
    level = logging.DEBUG if verbose else logging.INFO
    logging.basicConfig(
        level=level,
        format="%(asctime)s [%(levelname)s] %(message)s",
        datefmt="%Y-%m-%d %H:%M:%S",
    )


def normalise_gene_key(series: pd.Series) -> pd.Series:
    """
    Normalise gene symbols for reliable matching.

    Parameters
    ----------
    series
        Input gene key series.

    Returns
    -------
    pd.Series
        Upper-cased, stripped gene keys.
    """
    return series.astype(str).str.strip().str.upper()


def parse_bool_series(series: pd.Series) -> np.ndarray:
    """
    Parse a pandas Series into a boolean numpy array from common truthy tokens.

    Parameters
    ----------
    series
        Series to parse.

    Returns
    -------
    np.ndarray
        Boolean array.
    """
    vals = series.astype(str).str.strip().str.lower()
    return vals.isin({"true", "1", "t", "yes", "y"}).to_numpy()


def read_excel_sheet(path: str, sheet_name: str) -> pd.DataFrame:
    """
    Read an Excel sheet with robust defaults.

    Parameters
    ----------
    path
        Excel path.
    sheet_name
        Sheet name to read.

    Returns
    -------
    pd.DataFrame
        DataFrame with NA filled as empty strings for object columns.
    """
    df = pd.read_excel(path, sheet_name=sheet_name, dtype=object)
    df = df.copy()
    for col in df.columns:
        if df[col].dtype == object:
            df[col] = df[col].fillna("")
    return df


def ensure_out_prefix(path: str) -> str:
    """
    Convert an output path (possibly ending in .tsv/.xlsx) into a prefix.

    Parameters
    ----------
    path
        Output path or prefix.

    Returns
    -------
    str
        Prefix without extension.
    """
    if path.lower().endswith(".tsv"):
        return path[:-4]
    if path.lower().endswith(".xlsx"):
        return path[:-5]
    return path


def auto_detect_membership_columns(
    tier_df: pd.DataFrame,
    gene_key_col: str,
    include_regex: str,
    exclude_regex: str,
) -> List[str]:
    """
    Auto-detect boolean membership columns in a tier summary sheet.

    Strategy:
    - consider all columns except gene_key_col
    - keep those whose name matches include_regex (default catches in_* and *_present)
    - drop those matching exclude_regex (if provided)

    Parameters
    ----------
    tier_df
        Tier summary DataFrame.
    gene_key_col
        Column containing gene_key.
    include_regex
        Regex defining columns likely to be membership booleans.
    exclude_regex
        Regex for excluding columns.

    Returns
    -------
    list of str
        Detected membership columns.
    """
    cols = [c for c in tier_df.columns if c != gene_key_col]
    include = re.compile(include_regex, flags=re.IGNORECASE)
    keep = [c for c in cols if include.search(str(c))]

    if exclude_regex:
        exclude = re.compile(exclude_regex, flags=re.IGNORECASE)
        keep = [c for c in keep if not exclude.search(str(c))]

    return keep


def derive_proteomics_class_from_master(df: pd.DataFrame) -> pd.Series:
    """
    Derive a conservative proteomics class from master Excel columns.

    Priority:
    1) Use existing 'prot_class' if present and non-empty.
    2) If numeric columns exist (unique peptides and coverage), derive:
       Strong: unique_peptides >= 2 AND coverage_pct >= 10
       Detected: unique_peptides > 0 OR coverage_pct > 0
       None: otherwise
    3) Else if internal/public presence flags exist, derive:
       Strong: internal AND public
       Detected: internal OR public
       None: neither
    4) Else fall back to proteomics_present_any_source:
       Detected if True else None.

    Parameters
    ----------
    df
        Merged DataFrame.

    Returns
    -------
    pd.Series
        Proteomics class per row.
    """
    # 1) Existing class
    if "prot_class" in df.columns:
        s = df["prot_class"].astype(str).str.strip()
        if s.ne("").any():
            return s.replace("", "None").fillna("None")

    # 2) Numeric metrics (best)
    if ("prot_unique_peptides_max" in df.columns) or ("prot_coverage_pct_max" in df.columns):
        uniq = pd.to_numeric(df.get("prot_unique_peptides_max", 0), errors="coerce").fillna(0.0)
        cov = pd.to_numeric(df.get("prot_coverage_pct_max", 0), errors="coerce").fillna(0.0)
        strong = (uniq >= 2.0) & (cov >= 10.0)
        detected = (uniq > 0.0) | (cov > 0.0)
        out = np.where(strong, "Strong", np.where(detected, "Detected", "None"))
        return pd.Series(out, index=df.index)

    # 3) Internal/public flags (useful discriminator)
    if ("proteomics_present_internal" in df.columns) and ("proteomics_present_public" in df.columns):
        internal = parse_bool_series(df["proteomics_present_internal"])
        public = parse_bool_series(df["proteomics_present_public"])
        strong = internal & public
        detected = internal | public
        out = np.where(strong, "Strong", np.where(detected, "Detected", "None"))
        return pd.Series(out, index=df.index)

    # 4) Fallback: any source
    if "proteomics_present_any_source" in df.columns:
        any_src = parse_bool_series(df["proteomics_present_any_source"])
        return pd.Series(np.where(any_src, "Detected", "None"), index=df.index)

    return pd.Series(["None"] * df.shape[0], index=df.index)


def normalise_ensembl_gene_id(series: pd.Series, strip_version: bool) -> pd.Series:
    """
    Normalise Ensembl gene IDs.

    Parameters
    ----------
    series
        Input Ensembl gene ID series.
    strip_version
        If True, drop version suffix after '.'.

    Returns
    -------
    pd.Series
        Normalised Ensembl IDs.
    """
    s = series.astype(str).str.strip()
    if strip_version:
        s = s.str.replace(r"\.\d+$", "", regex=True)
    return s

def normalise_biochem_score(series: pd.Series) -> Tuple[pd.Series, str]:
    """
    Normalise biochemical accessibility score to 0-1 if needed.

    Rules:
    - Convert to numeric (coerce errors to NaN)
    - If max > 1.5 and max <= 100.0, assume 0-100 and divide by 100
    - If max > 100.0, do not rescale (log a warning)
    - Fill NaN with 0.0

    Parameters
    ----------
    series
        Input score series.

    Returns
    -------
    (pd.Series, str)
        Normalised score and a description of the scaling applied.
    """
    s = pd.to_numeric(series, errors="coerce")
    max_val = float(np.nanmax(s.to_numpy())) if np.isfinite(np.nanmax(s.to_numpy())) else 0.0

    if max_val > 1.5 and max_val <= 100.0:
        s = s / 100.0
        scale_note = "scaled_0_100_to_0_1"
    elif max_val > 100.0:
        scale_note = "no_scaling_max_gt_100"
    else:
        scale_note = "assumed_0_1"

    s = s.fillna(0.0)
    s = s.clip(lower=0.0, upper=1.0)
    return s, scale_note


def compute_priority_score(
    df: pd.DataFrame,
    membership_cols: List[str],
    novelty_exclude_cols: Set[str],
    biochem_col: str,
    weights: Weights,
) -> pd.DataFrame:
    """
    Compute a transparent priority score and score components.

    Parameters
    ----------
    df
        Merged DataFrame with membership columns and optional tractability/proteomics/biochem.
    membership_cols
        Columns used for membership counting.
    novelty_exclude_cols
        Subset of membership columns that mark a gene as "known" (removes novelty bonus).
    biochem_col
        Name of biochemical accessibility score column.
    weights
        Scoring weights.

    Returns
    -------
    pd.DataFrame
        DataFrame with added scoring columns.
    """
    out = df.copy()

    components: List[List[str]] = [[] for _ in range(out.shape[0])]
    scores = np.zeros(out.shape[0], dtype=float)

    # Membership count
    if membership_cols:
        mem = np.zeros((out.shape[0], len(membership_cols)), dtype=bool)
        for j, c in enumerate(membership_cols):
            mem[:, j] = parse_bool_series(out[c]) if c in out.columns else False
        n_mem = mem.sum(axis=1).astype(int)
    else:
        n_mem = np.zeros(out.shape[0], dtype=int)

    out["n_memberships"] = n_mem
    scores += n_mem.astype(float) * float(weights.per_membership_true)
    for i, n in enumerate(n_mem.tolist()):
        if n > 0:
            components[i].append(f"memberships:{n}*{weights.per_membership_true:g}")

    # Proteomics class (derived)
    out["prot_class"] = derive_proteomics_class_from_master(out).astype(str).str.strip().replace("", "None").fillna("None")
    prot = out["prot_class"].astype(str).str.strip().str.title()
    for i, pc in enumerate(prot.tolist()):
        if pc == "Strong":
            scores[i] += float(weights.proteomics_strong)
            components[i].append(f"prot:Strong+{weights.proteomics_strong:g}")
        elif pc == "Detected":
            scores[i] += float(weights.proteomics_detected)
            components[i].append(f"prot:Detected+{weights.proteomics_detected:g}")

    out["prot_any_detected_or_strong"] = prot.isin({"Detected", "Strong"})

    # Tractability (Open Targets) if present
    def bool_col(name: str) -> Optional[np.ndarray]:
        if name not in out.columns:
            return None
        return parse_bool_series(out[name])

    sm = bool_col("ot_any_small_molecule_tractable")
    ab = bool_col("ot_any_antibody_tractable")
    pr = bool_col("ot_any_protac_tractable")

    if sm is not None:
        idx = np.where(sm)[0]
        scores[idx] += float(weights.tract_small_molecule)
        for i in idx.tolist():
            components[i].append(f"tract:SM+{weights.tract_small_molecule:g}")

    if ab is not None:
        idx = np.where(ab)[0]
        scores[idx] += float(weights.tract_antibody)
        for i in idx.tolist():
            components[i].append(f"tract:Ab+{weights.tract_antibody:g}")

    if pr is not None:
        idx = np.where(pr)[0]
        scores[idx] += float(weights.tract_protac)
        for i in idx.tolist():
            components[i].append(f"tract:PROTAC+{weights.tract_protac:g}")

    tract_any = np.zeros(out.shape[0], dtype=bool)
    for arr in [sm, ab, pr]:
        if arr is not None:
            tract_any |= arr
    out["ot_any_tractable"] = tract_any

    # Biochemical accessibility (continuous)
    if biochem_col and biochem_col in out.columns:
        biochem_norm, scale_note = normalise_biochem_score(out[biochem_col])
        out["biochemical_accessibility_score_norm"] = biochem_norm
        out["biochem_scaling_note"] = scale_note

        scores += biochem_norm.to_numpy(dtype=float) * float(weights.biochemical_accessibility)
        for i, v in enumerate(biochem_norm.to_numpy(dtype=float).tolist()):
            if v > 0.0:
                components[i].append(f"biochem:{v:.3f}*{weights.biochemical_accessibility:g}")
    else:
        out["biochemical_accessibility_score_norm"] = 0.0
        out["biochem_scaling_note"] = "missing"
        logging.warning("Biochemical score column not found: '%s' (biochem term will be 0)", biochem_col)

    # Novelty bonus: only if excluded lists provided
    novelty_mask = np.ones(out.shape[0], dtype=bool)
    if novelty_exclude_cols:
        for c in novelty_exclude_cols:
            if c in out.columns:
                novelty_mask &= ~parse_bool_series(out[c])
        novelty_mask &= (n_mem > 0)

        scores[novelty_mask] += float(weights.novelty_bonus)
        for i in np.where(novelty_mask)[0].tolist():
            components[i].append(f"novelty+{weights.novelty_bonus:g}")

    out["priority_score"] = scores
    out["score_components"] = [";".join(c) for c in components]

    # Heuristic candidate definition
    out["candidate_druggable_sperm_protein"] = (
        out["ot_any_tractable"].astype(bool)
        & out["prot_any_detected_or_strong"].astype(bool)
    )

    # Convenience: membership names
    if membership_cols:
        col_arr = np.array(membership_cols, dtype=object)
        mem_mask = np.zeros((out.shape[0], len(membership_cols)), dtype=bool)
        for j, c in enumerate(membership_cols):
            mem_mask[:, j] = parse_bool_series(out[c]) if c in out.columns else False
        out["membership_names"] = [
            "|".join(col_arr[row_mask].tolist()) if row_mask.any() else ""
            for row_mask in mem_mask
        ]
    else:
        out["membership_names"] = ""

    return out


def read_tsv(path: str) -> pd.DataFrame:
    """
    Read a tab-separated file robustly.

    Parameters
    ----------
    path
        Input TSV path.

    Returns
    -------
    pd.DataFrame
        DataFrame with empty strings for missing object values.
    """
    df = pd.read_csv(path, sep="\t", dtype=str).fillna("")
    return df

def write_outputs(
    out_prefix: str,
    ranked: pd.DataFrame,
    candidate: pd.DataFrame,
    topn: Optional[pd.DataFrame],
) -> None:
    """
    Write TSV and Excel outputs.

    Parameters
    ----------
    out_prefix
        Output prefix (no extension).
    ranked
        Ranked full table.
    candidate
        Candidate subset.
    topn
        Optional top-N subset.
    """
    out_dir = os.path.dirname(os.path.abspath(out_prefix)) or "."
    os.makedirs(out_dir, exist_ok=True)

    ranked_tsv = f"{out_prefix}.tsv"
    ranked_xlsx = f"{out_prefix}.xlsx"
    ranked.to_csv(ranked_tsv, sep="\t", index=False)
    logging.info("Wrote ranked TSV: %s rows -> %s", ranked.shape[0], ranked_tsv)

    cand_prefix = f"{out_prefix}__candidate_druggable_sperm_protein"
    cand_tsv = f"{cand_prefix}.tsv"
    cand_xlsx = f"{cand_prefix}.xlsx"
    candidate.to_csv(cand_tsv, sep="\t", index=False)
    logging.info("Wrote candidate TSV: %s rows -> %s", candidate.shape[0], cand_tsv)

    if topn is not None:
        top_prefix = f"{out_prefix}__top{topn.shape[0]}"
        top_tsv = f"{top_prefix}.tsv"
        top_xlsx = f"{top_prefix}.xlsx"
        topn.to_csv(top_tsv, sep="\t", index=False)
        logging.info("Wrote top-N TSV: %s rows -> %s", topn.shape[0], top_tsv)

    def write_excel(path: str, sheets: Dict[str, pd.DataFrame]) -> None:
        with pd.ExcelWriter(path, engine="openpyxl") as writer:
            for sheet_name, df in sheets.items():
                df.to_excel(writer, sheet_name=sheet_name[:31], index=False)

    write_excel(
        ranked_xlsx,
        sheets={
            "ranked": ranked,
            "candidate_druggable_sperm_protein": candidate,
            **({"topN": topn} if topn is not None else {}),
        },
    )
    logging.info("Wrote ranked Excel workbook -> %s", ranked_xlsx)

    write_excel(cand_xlsx, sheets={"candidate_druggable_sperm_protein": candidate})
    logging.info("Wrote candidate Excel workbook -> %s", cand_xlsx)

    if topn is not None:
        top_prefix = f"{out_prefix}__top{topn.shape[0]}"
        top_xlsx = f"{top_prefix}.xlsx"
        write_excel(top_xlsx, sheets={"topN": topn})
        logging.info("Wrote top-N Excel workbook -> %s", top_xlsx)


def parse_args(argv: Optional[Sequence[str]] = None) -> argparse.Namespace:
    """
    Parse command-line arguments.

    Returns
    -------
    argparse.Namespace
        Parsed arguments.
    """
    p = argparse.ArgumentParser(
        description="Prioritise druggable sperm targets from a master Excel workbook."
    )
    p.add_argument("--excel_in", required=True, help="Input master Excel workbook (biochem annotated).")
    p.add_argument("--gene_master_sheet", default="Genes_Master", help="Sheet containing per-gene master table.")
    p.add_argument("--tier_sheet", default="Tier_Summary_With_Omics", help="Sheet containing tier/membership booleans.")
    p.add_argument("--gene_key_column", default="gene_key", help="Gene symbol column name (must exist in both sheets).")

    p.add_argument(
        "--membership_include_regex",
        default=r"^(in_|.*_present$|.*_present_.*|clinvar_.*present$|sperm_.*present$|lit_support_.*)$",
        help="Regex to auto-detect membership columns from tier sheet.",
    )
    p.add_argument(
        "--membership_exclude_regex",
        default=r"^(gene_id|gene_key|approved_symbol|symbol)$",
        help="Regex to exclude columns from membership detection.",
    )
    p.add_argument(
        "--novelty_exclude_regex",
        default="literature",
        help="Regex over membership column names; matches remove novelty bonus (default: 'literature').",
    )

    p.add_argument(
        "--biochem_score_column",
        default="biochemical_accessibility_score",
        help="Biochemical accessibility score column in Gene_Master.",
    )
    p.add_argument(
        "--gene_id_column",
        default="ensembl_gene_id",
        help="Ensembl gene id column in Genes_Master (e.g. ensembl_gene_id).",
    )

    p.add_argument("--tractability_tsv", default="", help="Optional TSV containing Open Targets tractability fields.")
    p.add_argument("--tractability_gene_id_column", default="gene_id", help="Gene id column in tractability TSV.")

    p.add_argument("--strip_ensembl_version", action="store_true", help="Strip .<version> from Ensembl IDs before merging.")

    # Weights
    p.add_argument("--w_per_membership", type=float, default=1.0)
    p.add_argument("--w_prot_detected", type=float, default=1.0)
    p.add_argument("--w_prot_strong", type=float, default=3.0)
    p.add_argument("--w_tract_sm", type=float, default=4.0)
    p.add_argument("--w_tract_ab", type=float, default=2.0)
    p.add_argument("--w_tract_protac", type=float, default=2.0)
    p.add_argument("--w_novelty", type=float, default=1.5)
    p.add_argument("--w_biochem", type=float, default=3.0)

    p.add_argument("--min_memberships", type=int, default=1, help="Filter: minimum memberships required.")
    p.add_argument("--top_n", type=int, default=0, help="Optional: also write top N rows as separate outputs.")
    p.add_argument("--out_prefix", required=True, help="Output prefix (writes both TSV and XLSX).")
    p.add_argument("--verbose", action="store_true")
    return p.parse_args(argv)



def main(argv: Optional[Sequence[str]] = None) -> int:
    """
    Run the prioritisation workflow.

    This version:
    - normalises gene_key early and de-duplicates by gene_key
    - creates gene_id ONCE from args.gene_id_column (default: ensembl_gene_id)
    - merges Open Targets tractability ONCE (optional) into gene_master
    - then merges tier/membership columns
    - computes score, filters, sorts, and writes TSV+XLSX outputs
    """
    args = parse_args(argv)
    setup_logger(verbose=args.verbose)
    start = datetime.now()

    if not os.path.isfile(args.excel_in):
        raise SystemExit(f"excel_in not found: {args.excel_in}")

    out_prefix = ensure_out_prefix(args.out_prefix)
    logging.info("Input Excel: %s", args.excel_in)
    logging.info("Output prefix: %s", out_prefix)

    logging.info("Reading sheets: %s and %s", args.gene_master_sheet, args.tier_sheet)
    gene_master = read_excel_sheet(args.excel_in, args.gene_master_sheet)
    tier = read_excel_sheet(args.excel_in, args.tier_sheet)

    # Validate required columns
    if args.gene_key_column not in gene_master.columns:
        raise SystemExit(f"Missing '{args.gene_key_column}' in sheet {args.gene_master_sheet}")
    if args.gene_key_column not in tier.columns:
        raise SystemExit(f"Missing '{args.gene_key_column}' in sheet {args.tier_sheet}")

    # Normalise gene_key early (needed for all merges)
    gene_master = gene_master.copy()
    tier = tier.copy()
    gene_master[args.gene_key_column] = normalise_gene_key(gene_master[args.gene_key_column])
    tier[args.gene_key_column] = normalise_gene_key(tier[args.gene_key_column])

    # De-duplicate by gene_key conservatively
    if gene_master[args.gene_key_column].duplicated().any():
        dup_n = int(gene_master[args.gene_key_column].duplicated().sum())
        logging.warning("Gene_Master has duplicated gene_key entries (%s); keeping first", dup_n)
        gene_master = gene_master.drop_duplicates(subset=[args.gene_key_column], keep="first")

    if tier[args.gene_key_column].duplicated().any():
        dup_n = int(tier[args.gene_key_column].duplicated().sum())
        logging.warning("Tier sheet has duplicated gene_key entries (%s); keeping first", dup_n)
        tier = tier.drop_duplicates(subset=[args.gene_key_column], keep="first")

    logging.info("Gene_Master: %s rows, %s columns", gene_master.shape[0], gene_master.shape[1])
    logging.info("Tier sheet: %s rows, %s columns", tier.shape[0], tier.shape[1])

    # Create gene_id ONCE from args.gene_id_column (default: ensembl_gene_id)
    if args.gene_id_column not in gene_master.columns:
        logging.warning(
            "Gene id column '%s' not found in Genes_Master; tractability merge will be skipped",
            args.gene_id_column,
        )
        gene_master["gene_id"] = ""
    else:
        gene_master["gene_id"] = normalise_ensembl_gene_id(
            gene_master[args.gene_id_column],
            strip_version=bool(args.strip_ensembl_version),
        )
        n_nonempty = int((gene_master["gene_id"].astype(str).str.strip() != "").sum())
        logging.info(
            "Created 'gene_id' from Genes_Master column '%s' (non-empty: %s/%s)",
            args.gene_id_column,
            n_nonempty,
            gene_master.shape[0],
        )

    # Merge Open Targets tractability ONCE (optional)
    if args.tractability_tsv:
        if (gene_master["gene_id"].astype(str).str.strip() == "").all():
            logging.warning(
                "tractability_tsv provided but 'gene_id' is empty for all rows; skipping tractability merge"
            )
        else:
            logging.info("Loading tractability TSV: %s", args.tractability_tsv)
            tract = read_tsv(args.tractability_tsv)

            if args.tractability_gene_id_column not in tract.columns:
                raise SystemExit(
                    f"Tractability TSV missing column '{args.tractability_gene_id_column}'"
                )

            tract = tract.rename(columns={args.tractability_gene_id_column: "gene_id"})
            tract["gene_id"] = normalise_ensembl_gene_id(
                tract["gene_id"],
                strip_version=bool(args.strip_ensembl_version),
            )

            expected_ot = [
                "ot_any_small_molecule_tractable",
                "ot_any_antibody_tractable",
                "ot_any_protac_tractable",
                "ot_tractability_summary",
                "ot_approved_symbol",
            ]
            keep = ["gene_id"] + [c for c in expected_ot if c in tract.columns]

            if len(keep) == 1:
                logging.warning(
                    "No expected ot_* columns found in tractability TSV. First columns: %s",
                    ", ".join([str(c) for c in list(tract.columns)[:30]]),
                )
            else:
                tract = tract[keep].drop_duplicates(subset=["gene_id"], keep="first")
                gene_master = gene_master.merge(tract, on="gene_id", how="left")

                # Fill missing OT fields
                for c in [
                    "ot_any_small_molecule_tractable",
                    "ot_any_antibody_tractable",
                    "ot_any_protac_tractable",
                ]:
                    if c in gene_master.columns:
                        gene_master[c] = gene_master[c].fillna("False")
                for c in ["ot_tractability_summary", "ot_approved_symbol"]:
                    if c in gene_master.columns:
                        gene_master[c] = gene_master[c].fillna("")

                logging.info(
                    "After tractability merge (Genes_Master): %s rows, %s columns",
                    gene_master.shape[0],
                    gene_master.shape[1],
                )

                if "ot_any_small_molecule_tractable" in gene_master.columns:
                    counts = (
                        gene_master["ot_any_small_molecule_tractable"]
                        .astype(str)
                        .str.strip()
                        .str.lower()
                        .value_counts()
                        .head(10)
                        .to_dict()
                    )
                    logging.info(
                        "ot_any_small_molecule_tractable value counts (top 10): %s",
                        counts,
                    )
    else:
        logging.info("No tractability TSV provided; OT columns will be missing/False")

    # Detect membership columns on tier sheet
    membership_cols = auto_detect_membership_columns(
        tier_df=tier,
        gene_key_col=args.gene_key_column,
        include_regex=args.membership_include_regex,
        exclude_regex=args.membership_exclude_regex,
    )
    logging.info("Detected %s membership columns in tier sheet", len(membership_cols))
    if args.verbose and membership_cols:
        logging.debug("Membership columns: %s", ", ".join(membership_cols))

    # Merge tier membership columns into gene_master
    merged = gene_master.merge(
        tier[[args.gene_key_column] + membership_cols],
        on=args.gene_key_column,
        how="left",
    )

    # Fill missing membership cols with False-like values
    for c in membership_cols:
        if c in merged.columns:
            merged[c] = merged[c].fillna("False")

    # Novelty excluded membership columns
    novelty_exclude_cols: Set[str] = set()
    if args.novelty_exclude_regex:
        patt = re.compile(args.novelty_exclude_regex, flags=re.IGNORECASE)
        novelty_exclude_cols = {c for c in membership_cols if patt.search(c)}
        logging.info(
            "Novelty exclude membership columns matched by regex '%s': %s",
            args.novelty_exclude_regex,
            ", ".join(sorted(novelty_exclude_cols)) if novelty_exclude_cols else "(none)",
        )
    else:
        logging.info("No novelty exclude regex provided; novelty bonus will not be applied")

    # Weights
    weights = Weights(
        per_membership_true=args.w_per_membership,
        proteomics_detected=args.w_prot_detected,
        proteomics_strong=args.w_prot_strong,
        tract_small_molecule=args.w_tract_sm,
        tract_antibody=args.w_tract_ab,
        tract_protac=args.w_tract_protac,
        novelty_bonus=args.w_novelty,
        biochemical_accessibility=args.w_biochem,
    )
    logging.info("Scoring weights: %s", weights)

    # Score
    scored = compute_priority_score(
        df=merged.rename(columns={args.gene_key_column: "gene_key"}),
        membership_cols=membership_cols,
        novelty_exclude_cols=novelty_exclude_cols,
        biochem_col=args.biochem_score_column,
        weights=weights,
    )

    # Restore canonical gene_key column name in outputs
    scored = scored.rename(columns={"gene_key": args.gene_key_column})

    # Filter by minimum memberships
    before = scored.shape[0]
    scored["n_memberships"] = (
        pd.to_numeric(scored["n_memberships"], errors="coerce")
        .fillna(0)
        .astype(int)
    )
    ranked = scored[scored["n_memberships"] >= int(args.min_memberships)].copy()
    logging.info(
        "Filter min_memberships >= %s: %s -> %s rows",
        args.min_memberships,
        before,
        ranked.shape[0],
    )

    # Diagnostics
    prot_counts_all = scored["prot_class"].value_counts(dropna=False).to_dict()
    logging.info("Proteomics class counts (all scored genes): %s", prot_counts_all)

    prot_counts_ranked = ranked["prot_class"].value_counts(dropna=False).to_dict()
    logging.info("Proteomics class counts (ranked after filters): %s", prot_counts_ranked)

    if "ot_any_tractable" in ranked.columns:
        logging.info(
            "Tractability any=True (ranked): %s",
            int(ranked["ot_any_tractable"].astype(bool).sum()),
        )
    else:
        logging.info("ot_any_tractable not present; tractability will be False for all rows")

    # Sort with tie-breakers
    ranked["prot_rank"] = (
        ranked["prot_class"].map({"Strong": 2, "Detected": 1, "None": 0}).fillna(0).astype(int)
    )
    ranked["tract_rank"] = ranked.get("ot_any_tractable", False).astype(int)

    ranked = (
        ranked.sort_values(
            by=["priority_score", "tract_rank", "prot_rank", "n_memberships", args.gene_key_column],
            ascending=[False, False, False, False, True],
        )
        .drop(columns=["prot_rank", "tract_rank"], errors="ignore")
    )

    # Candidate subset
    candidate = ranked[ranked["candidate_druggable_sperm_protein"].astype(bool)].copy()

    # Optional top N
    topn: Optional[pd.DataFrame] = None
    if int(args.top_n) > 0:
        topn = ranked.head(int(args.top_n)).copy()

    # Column ordering
    front = [
        args.gene_key_column,
        "gene_id",
        "priority_score",
        "score_components",
        "candidate_druggable_sperm_protein",
        "n_memberships",
        "membership_names",
        "prot_class",
        "prot_any_detected_or_strong",
        "ot_any_tractable",
        "ot_any_small_molecule_tractable",
        "ot_any_antibody_tractable",
        "ot_any_protac_tractable",
        "ot_approved_symbol",
        "ot_tractability_summary",
        args.biochem_score_column,
        "biochemical_accessibility_score_norm",
        "biochem_scaling_note",
    ]
    cols = [c for c in front if c in ranked.columns] + [c for c in ranked.columns if c not in set(front)]
    ranked = ranked[cols]
    candidate = candidate[[c for c in cols if c in candidate.columns]]

    logging.info("Ranked rows: %s", ranked.shape[0])
    logging.info("Candidate druggable sperm protein rows: %s", candidate.shape[0])

    # Write outputs
    write_outputs(out_prefix=out_prefix, ranked=ranked, candidate=candidate, topn=topn)

    elapsed = datetime.now() - start
    logging.info("Done. Elapsed time: %s", str(elapsed).split(".")[0])
    return 0


if __name__ == "__main__":
    raise SystemExit(main())